{{- if .Values.inferencePool }}
apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferencePool
metadata:
  name: {{ .Values.modelServiceName }}-inference-pool
  namespace: {{ .Release.Namespace }}
spec:
  extensionRef:
    failureMode: FailClose
    group: ""
    kind: Service
    name: {{ .Values.modelServiceName }}-epp-service
  selector:
    llm-d.ai/inferenceServing: "true"
    llm-d.ai/model: {{ .Values.modelServiceName }}
  targetPortNumber: 8000
{{- end }}
