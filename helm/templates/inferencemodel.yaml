{{- if .Values.inferenceModel }}
apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferenceModel
metadata:
  labels:
    llm-d.ai/inferenceServing: "true"
    llm-d.ai/model: {{ .Values.modelServiceName }}
  name: {{ .Values.modelServiceName }}
  namespace: {{ .Release.Namespace }}
spec:
  modelName: ibm-granite/granite-3.3-2b-base
  poolRef:
    group: inference.networking.x-k8s.io
    kind: InferencePool
    name: {{ .Values.modelServiceName }}-inference-pool
{{- end }}
