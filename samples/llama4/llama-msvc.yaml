apiVersion: llm-d.ai/v1alpha1
kind: ModelService
metadata:
  name: llama-4-scout-17b-model-service
spec:
  decoupleScaling: false

  baseConfigMapRef:
    name: llama-4-base-config

  routing: 
    modelName: llama-4/scout/17b

  modelArtifacts:
    uri: pvc://llama4-pvc/path/to/model

  # describe decode pods
  decode:
    replicas: 1
    parallelism:
      tensor: 8
    acceleratorTypes:
      labelKey: nvidia.com/gpu.product
      labelValues:
        - NVIDIA-A100-SXM4-80GB
    containers:
    - name: "llm"
      image: busybox
      args:
      - "50000"
  
  # describe the prefill pods 
  prefill:
    replicas: 1
    parallelism:
      tensor: 8
    acceleratorTypes:
      labelKey: nvidia.com/gpu.product
      labelValues:
        - NVIDIA-A100-SXM4-80GB
    containers:
    - name: "llm"
      image: busybox
      args:
      - "50000"
