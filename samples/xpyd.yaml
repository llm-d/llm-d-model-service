apiVersion: llm-d.ai/v1alpha1
kind: ModelService
metadata:
  name: facebook-opt-125m-xpyd
spec:
  decoupleScaling: false

  baseConfigMapRef:
  
    # Note: xpyd uses the same baseconfig as nixl example
    name: universal-base-config

  routing: 
    modelName: facebook/opt-125m

  modelArtifacts:
    uri: hf://facebook/opt-125m

  # describe decode pods
  decode:
    replicas: 2
    acceleratorTypes:
      labelKey: nvidia.com/gpu.product
      labelValues:
        - NVIDIA-A100-SXM4-80GB
    initContainers: 
      - name: "routing-proxy"
        args: 
          - "--connector=nixl"
    containers:
    - name: "vllm"
      # This image includes LMCache and multiconnector support
      image: quay.io/llm-d/llm-d-dev@sha256:d6d212de0d1dc0f6da9877eab21800f62d7dd32d825bae9bf1692c4f6e017109
      args:
        - "--model"
        - "{{ .HFModelName }}"
        - "--enforce-eager"
        - "--kv-transfer-config"
        - '{"kv_connector":"NixlConnector","kv_role":"kv_both"}'
      env:
        - name: NIXL_ROLE
          value: RECVER
  
  # describe the prefill pods 
  prefill:
    replicas: 1
    acceleratorTypes:
      labelKey: nvidia.com/gpu.product
      labelValues:
        - NVIDIA-A100-SXM4-80GB
    containers:
      - name: "vllm"
        image: quay.io/llm-d/llm-d-dev@sha256:d6d212de0d1dc0f6da9877eab21800f62d7dd32d825bae9bf1692c4f6e017109
        args:
          - "--model"
          - "{{ .HFModelName }}"
          - "--enforce-eager"
          - "--kv-transfer-config"
          - '{"kv_connector":"NixlConnector","kv_role":"kv_both"}'
        env:  
          - name: VLLM_NIXL_SIDE_CHANNEL_PORT
            value: "5557"
          - name: VLLM_NIXL_SIDE_CHANNEL_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: VLLM_LOGGING_LEVEL
            value: DEBUG
      
