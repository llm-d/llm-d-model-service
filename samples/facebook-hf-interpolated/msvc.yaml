apiVersion: llm-d.ai/v1alpha1
kind: ModelService
metadata:
  name: facebook-opt-125m
spec:
  decoupleScaling: false

  baseConfigMapRef:
    name: generic-base-config

  routing: 
    modelName: facebook/opt-125m

  modelArtifacts:
    uri: hf://facebook/opt-125m

  # describe decode pods
  decode:
    replicas: 1
    containers:
    - name: "vllm" 
      args: 
        - '{{ .HFModelName }}'
    
    # TODO: override or append for node affinity?
    # should be requiredDuringSchedulingIgnoredDuringExecution
    acceleratorTypes:
      labelKey: nvidia.com/gpu.product
      labelValues:
        - NVIDIA-A100-SXM4-80GB
  
  # describe the prefill pods 
  prefill:
    replicas: 1
    containers:
    - name: "vllm" 
      args: 
        - '{{ .HFModelName }}'
    acceleratorTypes:
      labelKey: nvidia.com/gpu.product
      labelValues:
        - NVIDIA-A100-SXM4-80GB
