apiVersion: llm-d.ai/v1alpha1
kind: ModelService
metadata:
  name: facebook-opt-125m-xpyd
spec:
  decoupleScaling: false

  baseConfigMapRef:
    name: generic-base-config

  routing: 
    modelName: facebook/opt-125m
    ports:
    - name: app_port
      port: 8000
    - name: internal_port
      port: 8200

  modelArtifacts:
    uri: pvc://facebook-pvc/path/to/opt-125m

  # describe decode pods
  decode:
    # Note a different replica count from spec.prefill.replicas
    replicas: 2
    containers:
    - name: "vllm"
      args:
      # Comes from baseconfig's volume mounts path
      - '/stored/models/{{ .ModelPath }}'
    acceleratorTypes:
      labelKey: nvidia.com/gpu.product
      labelValues:
        - NVIDIA-A100-SXM4-80GB
  
  # describe the prefill pods 
  prefill:
    replicas: 1
    containers:
    - name: "vllm"
      args:
      # Comes from baseconfig's volume mounts path
      - '/stored/models/{{ .ModelPath }}'
    acceleratorTypes:
      labelKey: nvidia.com/gpu.product
      labelValues:
        - NVIDIA-A100-SXM4-80GB
